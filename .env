DEVICE=cpu
VERB=2

### Lightweight llama model for testing purposes
LLM_MODEL_VERSION='llama3.2:1b'
### Alternative, heavier (8b) russian model
# LLM_MODEL_VERSION='d8rt8v/sambalingo-russian-chat-gguf:latest'

### Local ollama connection
# OLLAMA_HOST='http://localhost:11434'
### Docker ollama connection
OLLAMA_HOST='http://ollama:11434'
